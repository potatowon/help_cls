{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83bdaf8-5609-48ba-a76f-5ecdd1f627a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforms\n",
    "\n",
    "import monai\n",
    "import numpy as np\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Resample,\n",
    "    NormalizeIntensityd,\n",
    "    RandFlipd,\n",
    "    # RandRotate10d,\n",
    "    RandZoomd,\n",
    "    RandAffined,\n",
    "    RandGaussianNoised,   \n",
    "    ToTensord,\n",
    "    ScaleIntensity,\n",
    "    EnsureChannelFirst,\n",
    "    Resize\n",
    ")\n",
    "\n",
    "keys = ['image']\n",
    "\n",
    "train_transforms = Compose([\n",
    "    # LoadImaged(keys, image_only=True),\n",
    "    ScaleIntensity(),\n",
    "    EnsureChannelFirst(),\n",
    "    Resize((96, 96, 96))\n",
    "])\n",
    "# train_transforms = Compose([\n",
    "#     LoadImaged(keys, image_only=True),\n",
    "#     # ToTensord(keys),\n",
    "#     Resample(keys, \n",
    "#               (1.5, 1.5, 1.5)),\n",
    "\n",
    "#     NormalizeIntensityd('image', nonzero=True, channel_wise=True),\n",
    "#     RandFlipd(keys, prob=0.5, spatial_axis=0),# random by x-axis\n",
    "#     RandZoomd(keys, prob=0.5, min_zoom=0.9, max_zoom=1.1),\n",
    "#     RandAffined(\n",
    "#         keys,\n",
    "#         prob=0.5,\n",
    "#         rotate_range=(0, 0, np.pi/100),\n",
    "#         shear_range=(0.1, 0.1, 0.1),\n",
    "#         translate_range=(5, 5, 5),\n",
    "#         scale_range=(0.1, 0.1, 0.1),\n",
    "#         padding_mode='border'\n",
    "        \n",
    "#     ),\n",
    "#     RandGaussianNoised('image', prob=0.5, std=0.01),\n",
    "# ])\n",
    "\n",
    "# test_transforms = Compose([\n",
    "#     LoadImaged(keys, image_only=True),\n",
    "#     # ToTensord(keys),\n",
    "#     Resample(keys, (1.5, 1.5, 1.5)),\n",
    "#     NormalizeIntensityd('image', nonzero=True, channel_wise=True),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b76a74-f45e-437f-8085-db6a4f1f05ae",
   "metadata": {},
   "source": [
    "- dwi_adc_in_MNI_brain.nii.gz\n",
    "- dwi_b0_in_MNI_brain.nii.gz\n",
    "- flair_in_MNI_brain.nii.gz\n",
    "- pwi_K2_in_MNI_brain.nii.gz\n",
    "- pwi_rBF_in_MNI_brain.nii.gz\n",
    "- pwi_ref_in_MNI_brain.nii.gz\n",
    "- pwi_tMIP_in_MNI_brain.nii.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424ba396-66cb-4abf-bfe4-08b0e2b95d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data load\n",
    "import os\n",
    "import pandas as pd\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('/home/ncp/workspace/blockstorage/kyw/StudyHT_Open.csv')\n",
    "mni_img_dirs = glob.glob('/home/ncp/workspace/nasr/pub66n1/topic1/ImageData/*/MNI_Space/dwi_adc_in_MNI_brain.nii.gz')\n",
    "img_dirs = sorted(mni_img_dirs)\n",
    "train_img_dirs = img_dirs[:120]\n",
    "labels = list(map(int, list(df.loc[:119, 'GT_HTType']))) # label \n",
    "\n",
    "train_img_dirs, valid_img_dirs, train_labels, valid_labels = train_test_split(train_img_dirs,\n",
    "                                                                              labels,\n",
    "                                                                              test_size=0.3,\n",
    "                                                                              stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90062430-d4ac-4620-a980-3ad2b1fe6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(image_files=train_img_dirs, labels=train_labels, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "    \n",
    "valid_dataset = ImageDataset(image_files=valid_img_dirs, labels=valid_labels, transform=train_transforms)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=True, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4431095-e4bc-47db-a01e-3c3c5961f7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from resnet3d_pretrained import *\n",
    "\n",
    "cfg = {\n",
    "    'max_epochs' : 5,\n",
    "    # 'model' : 'densenet_model',\n",
    "    'opt' : 'adamw',\n",
    "    'lr' : 0.001,\n",
    "    'weight decay' : 1e-4,\n",
    "    'label_smoothing' : 0,\n",
    "    'lr_scheduler' : 'cosineannelinglr',\n",
    "    'lr_warmup_epochs' : 3,\n",
    "    'lr_min' : 0.0,\n",
    "    'val_resize_size' : 108,\n",
    "    'val_crop_size' : 96,\n",
    "    'train_crop_size' : 96,\n",
    "    'weight_decay' : 1e-4,\n",
    "    'img_dirs' : '/home/',\n",
    "    'work_dir' : '/home/',\n",
    "    'lr_warmup_decay' : 0.01,\n",
    "    'infererence_pretrain_dir' : '/home',\n",
    "    'seed' : 66\n",
    "}\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet101(shortcut_type='B')\n",
    "pretrained_dict = torch.load(\"/home/ncp/workspace/blockstorage/kyw/pretrainedmodel/resnet_101.pth\", map_location=torch.device('cpu') )\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed39011-b0a2-4822-bd99-e67d4b1835a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2093b66b-cfa2-4966-b9ba-aef870e98010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import (\n",
    "    BinaryAccuracy,\n",
    "    BinaryF1Score,\n",
    "    BinaryConfusionMatrix,\n",
    "    BinaryAUROC\n",
    ")\n",
    "# loss, optimizer and scheduler\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if cfg['opt'] == 'adamw':\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=cfg['lr'],  weight_decay=cfg['weight_decay'])\n",
    "\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=cfg['max_epochs'], eta_min=cfg['lr_min'])\n",
    "\n",
    "## define metrics\n",
    "accuracy = BinaryAccuracy()\n",
    "f1 =  BinaryF1Score()\n",
    "auroc =  BinaryAUROC()\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            all_preds.append(torch.argmax(outputs, dim=1))\n",
    "            \n",
    "            all_targets.append(target)\n",
    "\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    acc = accuracy(all_preds, all_targets)\n",
    "    f1_score = f1(all_preds, all_targets)\n",
    "    # auroc_score = auroc(all_preds, all_targets)\n",
    "\n",
    "    return acc, f1_score\n",
    "                             \n",
    "\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c82f0d3-72b8-4e45-998c-520784ac0c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [03:29, 34.95s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Evaluation on validation set\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m val_acc, val_f1, val_auroc \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Update the learing late\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Acc : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val F1 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in range(cfg['max_epochs']):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    val_acc, val_f1, val_auroc = evaluate(model, valid_loader)\n",
    "\n",
    "    # Update the learing late\n",
    "    # scheduler.step()\n",
    "    # print(f\"Epoch[{epoch+1/cfg['max_epochs']}], Loss: {loss.item():.4f}, Val Acc : {val_acc:.4f}, Val F1 : {val_f1:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f93b8-c31a-4993-b1a7-855ef6dc8491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefcde7-b79b-4109-9f16-6b6867658b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbdd78d-c2c1-443b-9b3d-0582ee062b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65434c-c5f4-4a5e-85cc-88a8ba490858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e259d-2995-475c-81df-bd5e6d4b8036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f4590-6ed0-47b8-9422-dea163ec25a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
